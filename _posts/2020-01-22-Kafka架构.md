---
layout: post
title: "Kafka架构"
date: 2021-04-23
categories: 大数据 Kafka
tags: 大数据 Kafka
updateTime: 2020-04-30
---

* content
{:toc}
## [Kafka架构](https://honeypps.com/mq/deep-interpretation-of-kafka-data-reliability/)
> [Kafka](https://kafka.apache.org/documentation/#gettingStarted)是由Apache软件基金会开发的一个开源流处理平台，由Scala和Java编写。Kafka是一种高吞吐量的分布式发布订阅消息系统，它可以处理消费者在网站中的所有动作流数据。

### 1.  场景
> xx将监播数据推送（push)到kafka,xx实时拉取（pull) 数据并消费。

### 2.  架构

![kafak架构](\image\mq\kafka\2021-11-01_kafka架构.png)

​		kafka集群一般有若干个Producer、2n+1个Broker、若干个Consuomer 及一个维护集群的zookeeper组成，Producer通过push方式将消息推送到Broker中，Consumer通过pull的方式将消息拉取到并消费。Zookeeper负责管理集群配置，产生Leader,以及消费组变更时重新平衡负载。

| 名称                                                         | 作用                                                         |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| Broker                                                       | 消息中间件<font color='red'>处理节点</font>，一个Kafka节点就是一个broker，<br/>一个或者多个Broker可以组成一个Kafka集群 |
| Topic                                                        | Kafka对消息进行归类                                          |
| Producer                                                     | 消息生产者，生产消息并发送到Broker的客户端                   |
| Consumer                                                     | 消息消费者，从Broker获取消息并消费的客户端                   |
| [ConsumerGroup](https://blog.csdn.net/lijingjingchn/article/details/85258883) | 由一个或多个Consumer组成，一条消息可以发送到多个<br/>ComsumerGroup,同一个GonsumerGroup共享groupId |
| Partition                                                    | 一个topic可以分为多个partition，每个partition内部是有序的    |



### 3.  ACK

> request.required.acks 参数设置
>
> 当producer向leader发送数据时，可以通过request.required.acks参数来设置数据可靠性的级别：

1：（默认）producer在ISR（In-Sync Replicas）中的leader已成功收到 并获取确认,如果leader挂了，则数据会丢失；

0：producer 不用等待来自broker的确认而继续发送下一条消息；

-1：producer需要等待ISR中的所有follower都确认接收到数据后才算一次发送完成，可靠性最高



### 4. 快

> 服务端：

- 日志存储：采用分段、追加方式，将顺序读写，提高访问速率；
- 批处理：减少网络IO；
- 批压缩：大文件压缩后，传输量小，则传输快；
- 偏移量：会记录每个consumer group offset ,便于下次直接读取；
- 缓冲区：先将数据写入页缓存（ACK确认）

> 客户端：

- 零拷贝：数据写入的是页缓存，如果命中，则直接读取，避免了从磁盘读取到页缓存过程；
- 避免垃圾回收：经过通道、缓冲区和页面缓存，减少了垃圾回收过程；
- 流并行处理：。将并发性深入到分区方案和使用者组的操作中，这实际上是Kafka中的一种负载均衡机制——将分区平均地分配到各个消费者中 （rebalance过程)

### 参考









#### 参考

[Kafka 朱小厮 相关使用](https://honeypps.com/tags/Kafka/)
