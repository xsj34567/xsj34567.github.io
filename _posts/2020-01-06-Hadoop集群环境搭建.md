---
layout: post
title: "Hadoop之集群环境搭建"
date: 2020-01-06
categories: 大数据 Hadoop NTP
tags: 大数据
updateTime: 2021-04-19
---

* content
{:toc}
## Hadoop集群
### 1. Hadoop 集群环境搭建

集群规划：2.10

### 2. Hadoop 安装配置

[Hadoop 2.10](http://mirrors.tuna.tsinghua.edu.cn/apache/hadoop/common/hadoop-2.10.0/hadoop-2.10.0.tar.gz)

#### 2.1. 安装目录

```sh

/home/meizhangzheng/data

#进入
cd /home/meizhangzheng

#下载
sudo wget http://mirrors.tuna.tsinghua.edu.cn/apache/hadoop/common/hadoop-2.10.0/hadoop-2.10.0.tar.gz

#3.3.0版本
https://archive.apache.org/dist/hadoop/common/hadoop-3.3.0/hadoop-3.3.0.tar.gz

#解压
sudo tar -zxvf hadoop-2.10.0.tar.gz -C /data

```
#### 2.2 配置环境

```shell
sudo vi .bash_profile

HADOOP_HOME=/home/meizhangzheng/data/hadoop-2.10.0
export PATH=$PATH:$HADOOP_HOME/bin
export PATH
```


​    

#### 2.3 在Hadoop中配置JAVA环境变量

```shell
cd /home/meizhangzheng/data/hadoop-2.10.0/etc/hadoop

sudo vi hadoop-env.sh
export JAVA_HOME=/home/meizhangzheng/jdk1.8.0_231

sudo vi yarn-env.sh
export JAVA_HOME=/home/meizhangzheng/jdk1.8.0_231

#在当前目录下设置slaves

sudo vi slaves 

slave1
slave2
```

#### 2.4 设置core-site.xml

```shell

fs.defaultFS	hdfs://master:9820 #指定NameNode文件系统
hadoop.tmp.dir	file://home/meizhagnzheng/hadoop/tmp 	#临时目录

```

#### 2.5 设置hdfs-site.xml

```shell
#指定NameNode存储meta和editlog的目录，建议先手动建好该目录

dfs.namenode.name.dir	file:/home/meizhangzheng/dfs/name  

dfs.datanode.data.dir	file:/home/meizhangzheng/dfs/data	#指定DataNode存储blocks的目录，建议先手动建好该目录
dfs.permissions	true	#防止出现不允许远程读写hdfs

dfs.replication	3	#指定数据副本数目

dfs.namenode.secondary.http-address	master:9001	#指定Secondary NameNode地址
```

#### 2.6 设置mapred-site.xml


     mapreduce.framework.name	yarn 	指定MR运行在yarn上
     mapreduce.jobhistory.address	master:10020	指定MR作业执行历史地址
     mapreduce.jobhistory.webapp.address	master:19888	指定MR作业历史web应用地址


#### 2.7  将环境同步到从节点

将master节点中 .bash_profile 、/home/meizhangzheng/data 分发到slave1、slave2 /home/meizhangzheng 目录

sudo scp .bash_profile meizhangzheng@slave1:~/

sudo scp -r data meizhangzheng@slave1:~/

### 3. hadoop 启动

#### 3.1 格式化命令

```sh
hadoop namenode -format
```

#### 3.2 启动

sudo ./home/meizhangzheng/data/hadoop-2.10.0/sbin/start-dfs.sh
sudo ./home/meizhangzheng/data/hadoop-2.10.0/sbin/start-yarn.sh

#### 3.3 查看服务

```sh
jps
```

查看集群状态:
[http://192.168.1.10:50070](http://192.168.1.10:50070)

查看yarn状态:
[http://192.168.1.10:8088](http://192.168.1.10:8088)

### 4. 异常 

(1)原来hadoop一直可以正常启动，有天在启动之后查看namenode的log发现如下in_use.lock (Permission denied)错误日志：

 	 1）：在原来正常的时候，有一次突然使用了原来不同的用户启动了一次hadoop。这种场景会产生一个in_use.lock 文件夹在你设置的目录中，这时候可以删除这个文件夹直接，然后重新启动
 	
 	 2）：在格式化hadoop的时候和当期启动的用户不是同一个，也会导致该问题。这个时候可以使用格式化hadoop的那个用户重新启动hadoop。也可以解决此错误。

[参考](https://blog.csdn.net/caoshichaocaoshichao/article/details/12879821)

  (2) 错误Name node is in safe mode的解决方法

   离开安全模式：hadoop dfsadmin -safemode leave

  (3) dataNode 未启动成功？   
    <1. 再次重启？
    <2. 检查nameNode VRESION clusterID 与 data/current/VERSION 中 clusterID 是否一致，如果不一致，则修改为一致的。